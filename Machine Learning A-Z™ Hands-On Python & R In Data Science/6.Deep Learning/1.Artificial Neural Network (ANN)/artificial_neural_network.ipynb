{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2787,
     "status": "ok",
     "timestamp": 1586428376540,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ZaTwK7ojXr2F",
    "outputId": "9991cc2b-cd5d-4e1e-c681-d32b9f4faa9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2782,
     "status": "ok",
     "timestamp": 1586428376541,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "VYP9cQTWbzuI",
    "outputId": "38e3588f-f2e3-436b-bdc5-2967d495155c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2780,
     "status": "ok",
     "timestamp": 1586428376541,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "38vKGE6Nb2RR",
    "outputId": "2abeb945-135e-460f-99e9-9967abe198d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2775,
     "status": "ok",
     "timestamp": 1586428376542,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "-M1KboxFb6OO",
    "outputId": "c7b742e2-7afb-4fb9-c6b4-ffeb3c4812f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1  2   3   4          5  6  7  8          9\n",
       "0     619   France  0  42   2        0.0  1  1  1  101348.88\n",
       "1     608    Spain  0  41   1   83807.86  1  0  1  112542.58\n",
       "2     502   France  0  42   8   159660.8  3  1  0  113931.57\n",
       "3     699   France  0  39   1        0.0  2  0  0   93826.63\n",
       "4     850    Spain  0  43   2  125510.82  1  1  1    79084.1\n",
       "...   ...      ... ..  ..  ..        ... .. .. ..        ...\n",
       "9995  771   France  1  39   5        0.0  2  1  0   96270.64\n",
       "9996  516   France  1  35  10   57369.61  1  1  1  101699.77\n",
       "9997  709   France  0  36   7        0.0  1  0  1   42085.58\n",
       "9998  772  Germany  1  42   3   75075.31  2  1  0   92888.52\n",
       "9999  792   France  0  28   4  130142.79  1  1  0   38190.78\n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       10000 non-null  object\n",
      " 1   1       10000 non-null  object\n",
      " 2   2       10000 non-null  object\n",
      " 3   3       10000 non-null  object\n",
      " 4   4       10000 non-null  object\n",
      " 5   5       10000 non-null  object\n",
      " 6   6       10000 non-null  object\n",
      " 7   7       10000 non-null  object\n",
      " 8   8       10000 non-null  object\n",
      " 9   9       10000 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(X).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2768,
     "status": "ok",
     "timestamp": 1586428376543,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ZcxwEon-b8nV",
    "outputId": "9c88c069-f799-4e3b-be4b-24d8e17611fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3  4   5   6          7  8  9  10         11\n",
       "0     1.0  0.0  0.0  619  0  42   2        0.0  1  1  1  101348.88\n",
       "1     0.0  0.0  1.0  608  0  41   1   83807.86  1  0  1  112542.58\n",
       "2     1.0  0.0  0.0  502  0  42   8   159660.8  3  1  0  113931.57\n",
       "3     1.0  0.0  0.0  699  0  39   1        0.0  2  0  0   93826.63\n",
       "4     0.0  0.0  1.0  850  0  43   2  125510.82  1  1  1    79084.1\n",
       "...   ...  ...  ...  ... ..  ..  ..        ... .. .. ..        ...\n",
       "9995  1.0  0.0  0.0  771  1  39   5        0.0  2  1  0   96270.64\n",
       "9996  1.0  0.0  0.0  516  1  35  10   57369.61  1  1  1  101699.77\n",
       "9997  1.0  0.0  0.0  709  0  36   7        0.0  1  0  1   42085.58\n",
       "9998  0.0  1.0  0.0  772  1  42   3   75075.31  2  1  0   92888.52\n",
       "9999  1.0  0.0  0.0  792  0  28   4  130142.79  1  1  0   38190.78\n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2  3   4   5          6  7  8  9          10\n",
       "0     0.0  0.0  619  0  42   2        0.0  1  1  1  101348.88\n",
       "1     0.0  1.0  608  0  41   1   83807.86  1  0  1  112542.58\n",
       "2     0.0  0.0  502  0  42   8   159660.8  3  1  0  113931.57\n",
       "3     0.0  0.0  699  0  39   1        0.0  2  0  0   93826.63\n",
       "4     0.0  1.0  850  0  43   2  125510.82  1  1  1    79084.1\n",
       "...   ...  ...  ... ..  ..  ..        ... .. .. ..        ...\n",
       "9995  0.0  0.0  771  1  39   5        0.0  2  1  0   96270.64\n",
       "9996  0.0  0.0  516  1  35  10   57369.61  1  1  1  101699.77\n",
       "9997  0.0  0.0  709  0  36   7        0.0  1  0  1   42085.58\n",
       "9998  1.0  0.0  772  1  42   3   75075.31  2  1  0   92888.52\n",
       "9999  0.0  0.0  792  0  28   4  130142.79  1  1  0   38190.78\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[:,1:]\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2760,
     "status": "ok",
     "timestamp": 1586428376544,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "De3UsJwXdfMz",
    "outputId": "dde0e114-7250-42b5-d54d-047faebba5e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.57873591 -0.57380915 -0.32622142 ...  0.64609167  0.97024255\n",
      "   0.02188649]\n",
      " [-0.57873591  1.74273971 -0.44003595 ... -1.54776799  0.97024255\n",
      "   0.21653375]\n",
      " [-0.57873591 -0.57380915 -1.53679418 ...  0.64609167 -1.03067011\n",
      "   0.2406869 ]\n",
      " ...\n",
      " [-0.57873591 -0.57380915  0.60498839 ... -1.54776799  0.97024255\n",
      "  -1.00864308]\n",
      " [ 1.72790383 -0.57380915  1.25683526 ...  0.64609167 -1.03067011\n",
      "  -0.12523071]\n",
      " [-0.57873591 -0.57380915  1.46377078 ...  0.64609167 -1.03067011\n",
      "  -1.07636976]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0.170424</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.469311</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>1.108382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-2.312802</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.747592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-1.195351</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.946079</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>0.575076</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>1.487464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>0.467955</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>1.278558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>2.063884</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>1.723821</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>0.806010</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.560069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-0.584891</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.660018</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>0.698607</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>1.093273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>1.484464</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-1.613554</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>0.608299</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.133249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0.905045</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>-0.373958</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>1.358909</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>1.414415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>-0.626278</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.087897</td>\n",
       "      <td>1.378686</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.846147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-0.284834</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.506303</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.326305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.578736  1.742740  0.170424 -1.095988 -0.469311 -0.004426 -1.225848   \n",
       "1     1.727904 -0.573809 -2.312802  0.912419  0.293517 -1.387538 -0.012892   \n",
       "2    -0.578736 -0.573809 -1.195351 -1.095988 -0.946079 -1.041760  0.575076   \n",
       "3    -0.578736  1.742740  0.035916  0.912419  0.102810 -0.004426  0.467955   \n",
       "4    -0.578736  1.742740  2.063884 -1.095988  1.723821  1.032908  0.806010   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7995  1.727904 -0.573809 -0.584891 -1.095988 -0.660018 -0.350204  0.698607   \n",
       "7996 -0.578736  1.742740  1.484464 -1.095988 -1.613554 -0.350204  0.608299   \n",
       "7997 -0.578736 -0.573809  0.905045  0.912419 -0.373958 -0.004426  1.358909   \n",
       "7998 -0.578736  1.742740 -0.626278 -1.095988 -0.087897  1.378686 -1.225848   \n",
       "7999  1.727904 -0.573809 -0.284834 -1.095988  0.865639 -1.387538  0.506303   \n",
       "\n",
       "            7         8         9         10  \n",
       "0     0.807737  0.646092 -1.030670  1.108382  \n",
       "1    -0.911583  0.646092  0.970243 -0.747592  \n",
       "2    -0.911583  0.646092 -1.030670  1.487464  \n",
       "3    -0.911583  0.646092 -1.030670  1.278558  \n",
       "4     0.807737  0.646092  0.970243  0.560069  \n",
       "...        ...       ...       ...       ...  \n",
       "7995  0.807737  0.646092  0.970243  1.093273  \n",
       "7996 -0.911583  0.646092  0.970243  0.133249  \n",
       "7997  0.807737  0.646092 -1.030670  1.414415  \n",
       "7998  0.807737  0.646092  0.970243  0.846147  \n",
       "7999 -0.911583  0.646092 -1.030670  0.326305  \n",
       "\n",
       "[8000 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu',input_dim=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "\n",
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "# Use 'softmax' activation function for multi-class classification problem\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "# If dependent variable has a binary outcome then use 'binary_crossentropy'\n",
    "# If dependent variable has more than 2 outcomes then use 'categorical_crossentropy'\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31750,
     "status": "ok",
     "timestamp": 1586428405580,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "nHZ-LKv_ZRb3",
    "outputId": "6a90f176-803d-4b03-e65f-c05bda6f519c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7955\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8026\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8080\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8124\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8165\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8181\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8217\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8245\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8267\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8281\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8289\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8282\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8301\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8306\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8326\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8315\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8322\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8370\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8409\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8431\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8444\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8465\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8480\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8500\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8505\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8515\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8525\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8551\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8560\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8555\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8566\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8564\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8587\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8577\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8593\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8587\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8604: 0s - loss: 0.3408 - accuracy: 0.86\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8585\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8605\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8618\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8597\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8590\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8616\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8624\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8624\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8620\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8618\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8612\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8618\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8614\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8626\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8614\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8614\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8624\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8650\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8629\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8620\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8611\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8629\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8631\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8636\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8633\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8626\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8634\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8624\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8637\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8639\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8627\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8620\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8631\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8634\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8639\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8630\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8631\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8635\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8631\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8634\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8636\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8643\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8625\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8648\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8641\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8635\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8645\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8641\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8651\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8646\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8656\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8629\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8637\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8645\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8648\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8645\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21a68445dc0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31748,
     "status": "ok",
     "timestamp": 1586428405581,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "nIyEeQdRZwgs",
    "outputId": "a0f4d9ad-9a29-41dc-b101-9e7216d74dc0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted  Actual\n",
       "0          0       0\n",
       "1          0       1\n",
       "2          0       0\n",
       "3          0       0\n",
       "4          0       0\n",
       "5          1       1\n",
       "6          0       0\n",
       "7          0       0\n",
       "8          0       1\n",
       "9          1       1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.45)\n",
    "diff = np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)\n",
    "result = pd.DataFrame(diff)\n",
    "result.columns = ['Predicted','Actual']\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31746,
     "status": "ok",
     "timestamp": 1586428405581,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ci6K_r6LaF6P",
    "outputId": "09bd315f-7091-457f-b222-ce3998de57a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1518   77]\n",
      " [ 196  209]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8635\n",
      "F1_Score: 0.6049204052098408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "print('Accuracy: {}'.format(acc))\n",
    "print('F1_Score: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    ann = Sequential()\n",
    "    ann.add(Dense(units=6, activation='relu',input_dim=11))\n",
    "    ann.add(Dense(units=6, activation='relu'))\n",
    "    ann.add(Dense(units=1, activation='sigmoid'))\n",
    "    ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=build_classifier,batch_size=10,nb_epoch=100)\n",
    "accuracies = cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10,n_jobs=-1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7976250112056732\n",
      "Variance: 0.009277830184239713\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}\\nVariance: {}'.format(mean,variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the accuracy of our model around 79-80% with a variance of just 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Regularization to reduce overfitting if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropouts are applied to 'neuron' so that some of them some of them randomly becomes disable at each iteration\n",
    "# So aplying droputs to several layers to reduce overfitting but since while evaluating we got very less variance already (1%) so 'Dropout' won't give much change\n",
    "def build_classifier():\n",
    "    ann = Sequential()\n",
    "    ann.add(Dense(units=6, activation='relu',input_dim=11))\n",
    "    ann.add(Dropout(0.1))\n",
    "    ann.add(Dense(units=6, activation='relu'))\n",
    "    ann.add(Dropout(0.1))\n",
    "    ann.add(Dense(units=1, activation='sigmoid'))\n",
    "    ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DropoutClassifier = KerasClassifier(build_fn=build_classifier,batch_size=10,nb_epoch=100)\n",
    "accuracies = cross_val_score(estimator=DropoutClassifier,X=X_train,y=y_train,cv=10,n_jobs=-1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7963750123977661\n",
      "Variance: 0.009960076819250497\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}\\nVariance: {}'.format(mean,variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there's not much difference as variance comes to be 0.9% (around 1%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optim):\n",
    "    ann = Sequential()\n",
    "    ann.add(Dense(units=6, activation='relu',input_dim=11))\n",
    "    ann.add(Dense(units=6, activation='relu'))\n",
    "    ann.add(Dense(units=1, activation='sigmoid'))\n",
    "    ann.compile(optimizer=optim, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 809us/step - loss: 0.5487 - accuracy: 0.7853\n",
      "288/288 [==============================] - 0s 767us/step - loss: 0.5414 - accuracy: 0.7713\n",
      "288/288 [==============================] - 0s 788us/step - loss: 0.5625 - accuracy: 0.7786\n",
      "288/288 [==============================] - 0s 770us/step - loss: 0.5414 - accuracy: 0.7962\n",
      "288/288 [==============================] - 0s 802us/step - loss: 0.5312 - accuracy: 0.7936\n",
      "288/288 [==============================] - 0s 743us/step - loss: 0.5278 - accuracy: 0.7711\n",
      "288/288 [==============================] - 0s 760us/step - loss: 0.5497 - accuracy: 0.7924\n",
      "288/288 [==============================] - 0s 784us/step - loss: 0.5344 - accuracy: 0.7922\n",
      "288/288 [==============================] - 0s 787us/step - loss: 0.5544 - accuracy: 0.7713\n",
      "288/288 [==============================] - 0s 767us/step - loss: 0.5426 - accuracy: 0.7843\n",
      "288/288 [==============================] - 0s 770us/step - loss: 0.6092 - accuracy: 0.7560\n",
      "288/288 [==============================] - 0s 795us/step - loss: 0.5367 - accuracy: 0.7681\n",
      "288/288 [==============================] - 0s 805us/step - loss: 0.6270 - accuracy: 0.7142\n",
      "288/288 [==============================] - 0s 754us/step - loss: 0.5367 - accuracy: 0.7961\n",
      "288/288 [==============================] - 0s 760us/step - loss: 0.6165 - accuracy: 0.7018\n",
      "288/288 [==============================] - 0s 762us/step - loss: 0.5782 - accuracy: 0.7475\n",
      "288/288 [==============================] - 0s 814us/step - loss: 0.5892 - accuracy: 0.7485\n",
      "288/288 [==============================] - 0s 763us/step - loss: 0.5298 - accuracy: 0.7575\n",
      "288/288 [==============================] - 0s 753us/step - loss: 0.5509 - accuracy: 0.7725\n",
      "288/288 [==============================] - 0s 763us/step - loss: 0.5238 - accuracy: 0.7726\n",
      "288/288 [==============================] - 0s 698us/step - loss: 0.6228 - accuracy: 0.7469\n",
      "288/288 [==============================] - 0s 701us/step - loss: 0.6526 - accuracy: 0.6596\n",
      "288/288 [==============================] - 0s 715us/step - loss: 0.5379 - accuracy: 0.7956\n",
      "288/288 [==============================] - 0s 715us/step - loss: 0.5720 - accuracy: 0.7725\n",
      "288/288 [==============================] - 0s 736us/step - loss: 0.5992 - accuracy: 0.7214\n",
      "288/288 [==============================] - 0s 809us/step - loss: 0.5949 - accuracy: 0.7519\n",
      "288/288 [==============================] - 0s 972us/step - loss: 0.6887 - accuracy: 0.6092\n",
      "288/288 [==============================] - 0s 971us/step - loss: 0.5630 - accuracy: 0.7826\n",
      "288/288 [==============================] - 0s 965us/step - loss: 0.5851 - accuracy: 0.7365\n",
      "288/288 [==============================] - 0s 930us/step - loss: 0.6343 - accuracy: 0.6918\n",
      "288/288 [==============================] - 0s 859us/step - loss: 0.5561 - accuracy: 0.7529\n",
      "288/288 [==============================] - 0s 784us/step - loss: 0.6006 - accuracy: 0.7111\n",
      "288/288 [==============================] - 0s 789us/step - loss: 0.5795 - accuracy: 0.7194\n",
      "288/288 [==============================] - 0s 760us/step - loss: 0.7249 - accuracy: 0.5414\n",
      "288/288 [==============================] - 0s 781us/step - loss: 0.6045 - accuracy: 0.7336\n",
      "288/288 [==============================] - 0s 782us/step - loss: 0.5573 - accuracy: 0.7929\n",
      "288/288 [==============================] - 0s 767us/step - loss: 0.5971 - accuracy: 0.7654\n",
      "288/288 [==============================] - 0s 746us/step - loss: 0.5799 - accuracy: 0.7697\n",
      "288/288 [==============================] - 0s 770us/step - loss: 0.5068 - accuracy: 0.7940\n",
      "288/288 [==============================] - 0s 781us/step - loss: 0.5637 - accuracy: 0.7411\n",
      "288/288 [==============================] - 0s 755us/step - loss: 0.5324 - accuracy: 0.7971\n",
      "288/288 [==============================] - 0s 999us/step - loss: 0.6255 - accuracy: 0.6769\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7940\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7956\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.7293\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7883\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.7658\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7572\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6900\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7829\n",
      "288/288 [==============================] - 0s 944us/step - loss: 0.5494 - accuracy: 0.7907\n",
      "288/288 [==============================] - 0s 965us/step - loss: 0.5557 - accuracy: 0.7722\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.6010 - accuracy: 0.71 - 0s 968us/step - loss: 0.5914 - accuracy: 0.7260\n",
      "288/288 [==============================] - 0s 947us/step - loss: 0.6671 - accuracy: 0.6654\n",
      "288/288 [==============================] - 0s 961us/step - loss: 0.5907 - accuracy: 0.7447\n",
      "288/288 [==============================] - 0s 980us/step - loss: 0.6205 - accuracy: 0.6746\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7578\n",
      "288/288 [==============================] - 0s 943us/step - loss: 0.5492 - accuracy: 0.7640\n",
      "288/288 [==============================] - 0s 968us/step - loss: 0.5573 - accuracy: 0.7643\n",
      "288/288 [==============================] - 0s 989us/step - loss: 0.5747 - accuracy: 0.7707\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7944\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.6004\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.6740\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.7240\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6037\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.7551\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.6051\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5892 - accuracy: 0.7024\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.7701\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7517\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7658\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.7132\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7910\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7822\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7447\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7921\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.7435\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.6519\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.7828\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7947\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.6986\n",
      "288/288 [==============================] - 0s 986us/step - loss: 0.6665 - accuracy: 0.6463\n",
      "288/288 [==============================] - 0s 987us/step - loss: 0.6157 - accuracy: 0.6958\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.7272\n",
      "288/288 [==============================] - 0s 988us/step - loss: 0.5779 - accuracy: 0.7688\n",
      "288/288 [==============================] - 0s 958us/step - loss: 0.5930 - accuracy: 0.7414\n",
      "288/288 [==============================] - 0s 982us/step - loss: 0.5555 - accuracy: 0.7946\n",
      "288/288 [==============================] - 0s 961us/step - loss: 0.6296 - accuracy: 0.7018\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.7229\n",
      "288/288 [==============================] - 0s 979us/step - loss: 0.5615 - accuracy: 0.7961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5528 - accuracy: 0.7971\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6836\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.6857\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7882\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.7026\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7943\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.7175\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.7628\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.5331\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7704\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.7608\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.5218\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.7572\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7975\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7689\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.6043\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.6017\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7962\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6343\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7586\n",
      "225/225 [==============================] - 0s 977us/step - loss: 0.5395 - accuracy: 0.7881\n",
      "225/225 [==============================] - 0s 951us/step - loss: 0.5179 - accuracy: 0.7954\n",
      "225/225 [==============================] - 0s 992us/step - loss: 0.6687 - accuracy: 0.6453\n",
      "225/225 [==============================] - 0s 928us/step - loss: 0.5788 - accuracy: 0.7468\n",
      "225/225 [==============================] - 0s 942us/step - loss: 0.5536 - accuracy: 0.7869\n",
      "225/225 [==============================] - 0s 955us/step - loss: 0.5607 - accuracy: 0.7569\n",
      "225/225 [==============================] - 0s 937us/step - loss: 0.5552 - accuracy: 0.7962\n",
      "225/225 [==============================] - 0s 973us/step - loss: 0.5534 - accuracy: 0.7962\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.7237\n",
      "225/225 [==============================] - 0s 970us/step - loss: 0.6420 - accuracy: 0.6865\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7701\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.7210\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.7874\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5646\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.4779\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.7074\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6621\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.7748 - accuracy: 0.4054\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7957\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7553\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7371\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7597\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5866 - accuracy: 0.7176\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6888\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7556\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7872\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.5924\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.7596 - accuracy: 0.4842\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7957\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7901\n",
      "225/225 [==============================] - 0s 947us/step - loss: 0.5665 - accuracy: 0.7919\n",
      "225/225 [==============================] - 0s 959us/step - loss: 0.5560 - accuracy: 0.7857\n",
      "225/225 [==============================] - 0s 924us/step - loss: 0.5863 - accuracy: 0.7651\n",
      "225/225 [==============================] - 0s 941us/step - loss: 0.6199 - accuracy: 0.6837\n",
      "225/225 [==============================] - 0s 977us/step - loss: 0.5783 - accuracy: 0.7821\n",
      "225/225 [==============================] - 0s 951us/step - loss: 0.6096 - accuracy: 0.6725\n",
      "225/225 [==============================] - 0s 951us/step - loss: 0.7708 - accuracy: 0.5581\n",
      "225/225 [==============================] - 0s 955us/step - loss: 0.5607 - accuracy: 0.7635\n",
      "225/225 [==============================] - 0s 959us/step - loss: 0.5812 - accuracy: 0.7758\n",
      "225/225 [==============================] - 0s 946us/step - loss: 0.6173 - accuracy: 0.7256\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6179 - accuracy: 0.7362\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7886\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7943\n",
      "225/225 [==============================] - 0s 991us/step - loss: 0.5406 - accuracy: 0.7514\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7793\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7617\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7588\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7479\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5841 - accuracy: 0.7654\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7588\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7682\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6450\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.7015\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.6914\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5824\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5674\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.7442\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7910\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.7432\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.6915\n",
      "225/225 [==============================] - 0s 982us/step - loss: 0.6172 - accuracy: 0.7529\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.7201\n",
      "225/225 [==============================] - 0s 982us/step - loss: 0.5965 - accuracy: 0.7246\n",
      "225/225 [==============================] - 0s 967us/step - loss: 0.5841 - accuracy: 0.7593\n",
      "225/225 [==============================] - 0s 933us/step - loss: 0.7224 - accuracy: 0.6018\n",
      "225/225 [==============================] - 0s 942us/step - loss: 0.5559 - accuracy: 0.7764\n",
      "225/225 [==============================] - 0s 951us/step - loss: 0.5816 - accuracy: 0.7964\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.7264\n",
      "225/225 [==============================] - 0s 955us/step - loss: 0.5824 - accuracy: 0.7460\n",
      "225/225 [==============================] - 0s 973us/step - loss: 0.5744 - accuracy: 0.7660\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.7843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6517\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.5301\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.6440\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6628\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.6554\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.5411\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.5214\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7794\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.7961\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.7503\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.7522\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.7788\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6347\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7700\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8550 - accuracy: 0.3875\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.7150\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.7337\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.7797\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.7503\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7926\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.7342\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6377 - accuracy: 0.6832\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.7232\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5910 - accuracy: 0.7907\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6876\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.6425\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6050 - accuracy: 0.7583\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.7169\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5908\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.6981\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.6111\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.7015\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.7961\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.7458\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.7679\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7969\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7962\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7957\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.7961\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7846\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6185 - accuracy: 0.7300\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7829\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6568\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6499\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.9076 - accuracy: 0.4481\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7321\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.5589\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.7447\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6357 - accuracy: 0.7157\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.5457\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6637\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5840\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7385 - accuracy: 0.5271\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5635\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6009 - accuracy: 0.7679\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7969\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.4999\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.5757\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.7508\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.7197\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.7872\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7480 - accuracy: 0.5161\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.6960\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.9540 - accuracy: 0.2864\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.7511\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.7364\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5343 - accuracy: 0.7926\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7915 - accuracy: 0.3207\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7890\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7915\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6514\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7956\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8461 - accuracy: 0.4058\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7936 - accuracy: 0.4132\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.6621\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 0.7450\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.7536\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6513\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.6244\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6650\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.5619\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5968 - accuracy: 0.7089\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5866 - accuracy: 0.7311\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5984 - accuracy: 0.7040\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.7761\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7868\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7713 - accuracy: 0.4482\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.6938\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.6086\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.7258\n"
     ]
    }
   ],
   "source": [
    "ImprovedClassifier = KerasClassifier(build_fn=build_classifier)\n",
    "parameters = {'batch_size':[25,32, 64],\n",
    "             'nb_epoch':[100,500,1000],\n",
    "              'optim':['adam','RMSprop','SGD']}\n",
    "grid_search = GridSearchCV(estimator=ImprovedClassifier,param_grid=parameters,scoring='accuracy',cv=10)\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7975\n",
      "Best parameters: {'batch_size': 25, 'nb_epoch': 100, 'optim': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Accuracy: {}\\nBest parameters: {}'.format(best_accuracy,best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMwbl0jJoa05wuIU59y39H3",
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
